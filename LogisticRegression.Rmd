---
title: "LogisticRegression"
author: "Julian Nieto"
date: "April 8, 2019"
output: html_document
---

```{r}
train_data = read.csv("train.csv")
test_data = read.csv("test.csv")
```

```{r}
library(corrplot)

corr.d <- cor( train_data )
corr.d[ lower.tri( corr.d, diag = TRUE ) ] <- NA
corrplot( corr.d, type = "upper", diag = FALSE )

new_train_data = train_data[, -seq(8, 118)]

mylogit <- glm(`RadiantWin` ~ ., data = new_train_data, family = "binomial")
summary(mylogit)


ols <- glm(`RadiantWin` ~ ., data = train_data)

log_conf_mat=table(test_data$RadiantWin, as.numeric(predict(mylogit,test_data)>=.5))

(log_conf_mat[1,1] + log_conf_mat[2,2])/nrow(test_data)


```

```{r}
# load library
library(neuralnet)

# fit neural network
nn=neuralnet(`RadiantWin`~ ., data = train_data, hidden= 5,act.fct = "logistic",
                linear.output = FALSE)

plot(nn)


sum(predict(nn,test_data) > .5)
sum(test_data$RadiantWin)

nn_conf_mat = table(test_data$RadiantWin, as.numeric(predict(nn,test_data)>=.5))

(nn_conf_mat[1,1] + nn_conf_mat[2,2])/nrow(test_data)
```

Neural Network, logistic regresion, and random forest
